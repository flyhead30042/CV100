{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業\n",
    "請嘗試使用 keras 來定義一個直接預測 15 個人臉關鍵點坐標的檢測網路，以及適合這個網路的 loss function\n",
    "\n",
    "\n",
    "Hint: 參考前面的電腦視覺深度學習基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 範例\n",
    "接下來的程式碼會示範如何定義一個簡單的 CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 colab 環境的同學請執行以下程式碼\n",
    "# %tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n",
    "# import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "\n",
    "# import os\n",
    "# from google.colab import drive \n",
    "# drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n",
    "# %cd 'gdrive/My Drive'\n",
    "# os.system(\"mkdir cupoy_cv_part4\") # 可以自己改路徑\n",
    "# %cd cupoy_cv_part4 # 可以自己改路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料集以及做前處理的函數\n",
    "def load_data(dirname):\n",
    "    # 讀取 csv 文件\n",
    "    data = pd.read_csv(dirname)\n",
    "    # 過濾有缺失值的 row\n",
    "    data = data.dropna()\n",
    "\n",
    "    # 將圖片像素值讀取為 numpy array 的形態\n",
    "    data['Image'] = data['Image'].apply(lambda img: np.fromstring(img, sep=' ')).values \n",
    "\n",
    "    # 單獨把圖像 array 抽取出來\n",
    "    imgs = np.vstack(data['Image'].values)/255\n",
    "    # reshape 為 96 x 96\n",
    "    imgs = imgs.reshape(data.shape[0], 96, 96 ,1)\n",
    "    # 轉換為 float\n",
    "    imgs = imgs.astype(np.float32)\n",
    "    \n",
    "    # 提取坐標的部分\n",
    "    points = data.iloc[:, :-1].to_numpy()\n",
    "\n",
    "    # 轉換為 float\n",
    "    points = points.astype(np.float32)\n",
    "\n",
    "    # normalize 坐標值到 [-0.5, 0.5]\n",
    "    points = points/96 - 0.5\n",
    "    \n",
    "    return imgs, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像資料: (2140, 96, 96, 1) \n",
      "關鍵點資料: (2140, 30)\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料\n",
    "DATA_ROOT = \"Facial_Keypoints_Detection\"\n",
    "training_file = os.path.join(DATA_ROOT,\"training.csv\" )\n",
    "imgs_train, points_train = load_data(dirname = training_file)\n",
    "print(\"圖像資料:\", imgs_train.shape, \"\\n關鍵點資料:\", points_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionV1_block(x, specs,channel_axis, name):\n",
    "    (br0, br1, br2, br3) = specs   # ((64,), (96,128), (16,32), (32,))\n",
    "    \n",
    "    '''Branch_0'''\n",
    "    branch_0 = Conv2d_bn(x, br0[0], (1, 1), name=name+\"_Branch_0\")\n",
    "\n",
    "    '''Branch_1'''    \n",
    "    branch_1 = Conv2d_bn(x, br1[0], (1, 1), name=name+\"_Branch_1\")\n",
    "    branch_1 = Conv2d_bn(branch_1, br1[1], (3, 3), name=name+\"_Branch_1_1\")\n",
    "\n",
    "    '''Branch_2'''\n",
    "    branch_2 = Conv2d_bn(x, br2[0], (1, 1), name=name+\"_Branch_2\")\n",
    "    branch_2 = Conv2d_bn(branch_2, br2[1], (3, 3), name=name+\"_Branch_2_1\")    \n",
    "\n",
    "    '''Branch_3'''\n",
    "    branch_3 = MaxPooling2D(pool_size=(3, 3), strides=(1,1), padding='same', name=name+\"_Branch_3\")(branch_2)\n",
    "    branch_3 = Conv2d_bn(branch_3, br3[0], (1, 1), name=name+\"_Branch_3_1\")        \n",
    "    \n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name=name+\"_Concatenated\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionV3_block(x, specs,channel_axis, name):\n",
    "    (br0, br1, br2, br3) = specs   # ((64,), (96,128), (16,32), (32,))\n",
    "    branch_0 = Conv2d_bn(x, br0[0], (1, 1), name=name+\"_Branch_0\")\n",
    "\n",
    "    branch_1 = Conv2d_bn(x, br1[0], (1, 1), name=name+\"_Branch_1\")\n",
    "    branch_1 = Conv2d_bn(branch_1, br1[1], (1, 3), name=name+\"_Branch_1_1\")\n",
    "    branch_1 = Conv2d_bn(branch_1, br1[1], (3, 1), name=name+\"_Branch_1_2\")\n",
    "\n",
    "    '''Branch_2'''\n",
    "    branch_2 = Conv2d_bn(x, br2[0], (1, 1), name=name+\"_Branch_2\")\n",
    "    branch_2 = Conv2d_bn(branch_2, br2[1], (3, 1), name=name+\"_Branch_2_1\")    \n",
    "    branch_2 = Conv2d_bn(branch_2, br2[1], (1, 3), name=name+\"_Branch_2_2\")    \n",
    "    \n",
    "    '''Branch_3'''\n",
    "    branch_3 = MaxPooling2D(pool_size=(3, 3), strides=(1,1), padding='same', name=name+\"_Branch_3\")(branch_2)\n",
    "    branch_3 = Conv2d_bn(branch_3, br3[0], (1, 1), name=name+\"_Branch_3_1\")        \n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name=name+\"_Concatenated\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2d_bn(x,filters,kernel_size,padding='same',strides=(1, 1),normalizer=True,activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        conv_name = name + '_conv'\n",
    "        bn_name = name + '_bn'\n",
    "        act_name = name + '_act'\n",
    "    else:\n",
    "        conv_name = None\n",
    "        bn_name = None\n",
    "        act_name = None\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Conv2D(\n",
    "            filters, kernel_size,\n",
    "            strides=strides, padding=padding,\n",
    "            use_bias=False, name=conv_name)(x)\n",
    "    if normalizer:\n",
    "        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    if activation:\n",
    "        x = Activation(activation, name=act_name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEe8WW2qJbap"
   },
   "outputs": [],
   "source": [
    "def VGG16_ResNet_Inception(include_top=True,input_tensor=None, input_shape=(224,224,1),\n",
    "          pooling='max',classes=1000):\n",
    " \n",
    "    img_input = Input(shape=input_shape)\n",
    "    \n",
    "    # Block 1    \n",
    "    x = Conv2d_bn(img_input,64, (3, 3), activation='relu', padding='same', name='block1_conv1')\n",
    "    x = Conv2d_bn(x,64, (3, 3), activation='relu', padding='same', name='block1_conv2')\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2d_bn(x,128, (3, 3), activation='relu', padding='same', name='block2_conv1')\n",
    "    x = Conv2d_bn(x,128, (3, 3), activation='relu', padding='same', name='block2_conv2')\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = InceptionV1_block(x, ((64,), (96,128), (16,32), (32,)), 3, 'Block_1')\n",
    "    x = InceptionV1_block(x, ((64,), (96,128), (16,32), (32,)), 3, 'Block_2')\n",
    "    x = InceptionV1_block(x, ((64,), (96,128), (16,32), (32,)), 3, 'Block_3')\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2d_bn(x,512, (3, 3), activation='relu', padding='same', name='block4_conv1')\n",
    "    x = Conv2d_bn(x,512, (3, 3), activation='relu', padding='same', name='block4_conv2')\n",
    "    x = Conv2d_bn(x,512, (3, 3), activation='relu', padding='same', name='block4_conv3')\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5 \n",
    "    #為什麼要加InceptionV3_block 原因?\n",
    "    x =InceptionV3_block(x, ((128,), (192,256), (32,64), (64,)), 3, 'Block_4')\n",
    "    x =InceptionV3_block(x, ((128,), (192,256), (32,64), (64,)), 3, 'Block_5')\n",
    "    x =InceptionV3_block(x, ((128,), (192,256), (32,64), (64,)), 3, 'Block_6')\n",
    "    x =MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "       #可以提醒學員為什麼要加avg或是max\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "            \n",
    "    inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_conv (Conv2D)      (None, 96, 96, 64)   576         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 96, 96, 64)   192         block1_conv1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 96, 96, 64)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_conv (Conv2D)      (None, 96, 96, 64)   36864       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 96, 96, 64)   192         block1_conv2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 96, 96, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 48, 48, 64)   0           block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_conv (Conv2D)      (None, 48, 48, 128)  73728       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_bn (BatchNormaliza (None, 48, 48, 128)  384         block2_conv1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_act (Activation)   (None, 48, 48, 128)  0           block2_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_conv (Conv2D)      (None, 48, 48, 128)  147456      block2_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_bn (BatchNormaliza (None, 48, 48, 128)  384         block2_conv2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_act (Activation)   (None, 48, 48, 128)  0           block2_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_2_conv (Conv2D)  (None, 24, 24, 16)   2048        block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_2_bn (BatchNorma (None, 24, 24, 16)   48          Block_1_Branch_2_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_2_act (Activatio (None, 24, 24, 16)   0           Block_1_Branch_2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_2_1_conv (Conv2D (None, 24, 24, 32)   4608        Block_1_Branch_2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_1_conv (Conv2D)  (None, 24, 24, 96)   12288       block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_2_1_bn (BatchNor (None, 24, 24, 32)   96          Block_1_Branch_2_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_1_bn (BatchNorma (None, 24, 24, 96)   288         Block_1_Branch_1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_2_1_act (Activat (None, 24, 24, 32)   0           Block_1_Branch_2_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_1_act (Activatio (None, 24, 24, 96)   0           Block_1_Branch_1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_3 (MaxPooling2D) (None, 24, 24, 32)   0           Block_1_Branch_2_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_0_conv (Conv2D)  (None, 24, 24, 64)   8192        block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_1_1_conv (Conv2D (None, 24, 24, 128)  110592      Block_1_Branch_1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_3_1_conv (Conv2D (None, 24, 24, 32)   1024        Block_1_Branch_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_0_bn (BatchNorma (None, 24, 24, 64)   192         Block_1_Branch_0_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_1_1_bn (BatchNor (None, 24, 24, 128)  384         Block_1_Branch_1_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_3_1_bn (BatchNor (None, 24, 24, 32)   96          Block_1_Branch_3_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_0_act (Activatio (None, 24, 24, 64)   0           Block_1_Branch_0_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_1_1_act (Activat (None, 24, 24, 128)  0           Block_1_Branch_1_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Branch_3_1_act (Activat (None, 24, 24, 32)   0           Block_1_Branch_3_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_1_Concatenated (Concatena (None, 24, 24, 256)  0           Block_1_Branch_0_act[0][0]       \n",
      "                                                                 Block_1_Branch_1_1_act[0][0]     \n",
      "                                                                 Block_1_Branch_2_1_act[0][0]     \n",
      "                                                                 Block_1_Branch_3_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_2_conv (Conv2D)  (None, 24, 24, 16)   4096        Block_1_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_2_bn (BatchNorma (None, 24, 24, 16)   48          Block_2_Branch_2_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_2_act (Activatio (None, 24, 24, 16)   0           Block_2_Branch_2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_2_1_conv (Conv2D (None, 24, 24, 32)   4608        Block_2_Branch_2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_1_conv (Conv2D)  (None, 24, 24, 96)   24576       Block_1_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_2_1_bn (BatchNor (None, 24, 24, 32)   96          Block_2_Branch_2_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_1_bn (BatchNorma (None, 24, 24, 96)   288         Block_2_Branch_1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_2_1_act (Activat (None, 24, 24, 32)   0           Block_2_Branch_2_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_1_act (Activatio (None, 24, 24, 96)   0           Block_2_Branch_1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_3 (MaxPooling2D) (None, 24, 24, 32)   0           Block_2_Branch_2_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_0_conv (Conv2D)  (None, 24, 24, 64)   16384       Block_1_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_1_1_conv (Conv2D (None, 24, 24, 128)  110592      Block_2_Branch_1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_3_1_conv (Conv2D (None, 24, 24, 32)   1024        Block_2_Branch_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_0_bn (BatchNorma (None, 24, 24, 64)   192         Block_2_Branch_0_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_1_1_bn (BatchNor (None, 24, 24, 128)  384         Block_2_Branch_1_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_3_1_bn (BatchNor (None, 24, 24, 32)   96          Block_2_Branch_3_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_0_act (Activatio (None, 24, 24, 64)   0           Block_2_Branch_0_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_1_1_act (Activat (None, 24, 24, 128)  0           Block_2_Branch_1_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Branch_3_1_act (Activat (None, 24, 24, 32)   0           Block_2_Branch_3_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_2_Concatenated (Concatena (None, 24, 24, 256)  0           Block_2_Branch_0_act[0][0]       \n",
      "                                                                 Block_2_Branch_1_1_act[0][0]     \n",
      "                                                                 Block_2_Branch_2_1_act[0][0]     \n",
      "                                                                 Block_2_Branch_3_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_2_conv (Conv2D)  (None, 24, 24, 16)   4096        Block_2_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_2_bn (BatchNorma (None, 24, 24, 16)   48          Block_3_Branch_2_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_2_act (Activatio (None, 24, 24, 16)   0           Block_3_Branch_2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_2_1_conv (Conv2D (None, 24, 24, 32)   4608        Block_3_Branch_2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_1_conv (Conv2D)  (None, 24, 24, 96)   24576       Block_2_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_2_1_bn (BatchNor (None, 24, 24, 32)   96          Block_3_Branch_2_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_1_bn (BatchNorma (None, 24, 24, 96)   288         Block_3_Branch_1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_2_1_act (Activat (None, 24, 24, 32)   0           Block_3_Branch_2_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_1_act (Activatio (None, 24, 24, 96)   0           Block_3_Branch_1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_3 (MaxPooling2D) (None, 24, 24, 32)   0           Block_3_Branch_2_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_0_conv (Conv2D)  (None, 24, 24, 64)   16384       Block_2_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_1_1_conv (Conv2D (None, 24, 24, 128)  110592      Block_3_Branch_1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_3_1_conv (Conv2D (None, 24, 24, 32)   1024        Block_3_Branch_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_0_bn (BatchNorma (None, 24, 24, 64)   192         Block_3_Branch_0_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_1_1_bn (BatchNor (None, 24, 24, 128)  384         Block_3_Branch_1_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_3_1_bn (BatchNor (None, 24, 24, 32)   96          Block_3_Branch_3_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_0_act (Activatio (None, 24, 24, 64)   0           Block_3_Branch_0_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_1_1_act (Activat (None, 24, 24, 128)  0           Block_3_Branch_1_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Branch_3_1_act (Activat (None, 24, 24, 32)   0           Block_3_Branch_3_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_3_Concatenated (Concatena (None, 24, 24, 256)  0           Block_3_Branch_0_act[0][0]       \n",
      "                                                                 Block_3_Branch_1_1_act[0][0]     \n",
      "                                                                 Block_3_Branch_2_1_act[0][0]     \n",
      "                                                                 Block_3_Branch_3_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           Block_3_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_conv (Conv2D)      (None, 12, 12, 512)  1179648     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_bn (BatchNormaliza (None, 12, 12, 512)  1536        block4_conv1_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_act (Activation)   (None, 12, 12, 512)  0           block4_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_conv (Conv2D)      (None, 12, 12, 512)  2359296     block4_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_bn (BatchNormaliza (None, 12, 12, 512)  1536        block4_conv2_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_act (Activation)   (None, 12, 12, 512)  0           block4_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_conv (Conv2D)      (None, 12, 12, 512)  2359296     block4_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_bn (BatchNormaliza (None, 12, 12, 512)  1536        block4_conv3_conv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_act (Activation)   (None, 12, 12, 512)  0           block4_conv3_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 6, 6, 512)    0           block4_conv3_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_2_conv (Conv2D)  (None, 6, 6, 32)     16384       block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_2_bn (BatchNorma (None, 6, 6, 32)     96          Block_4_Branch_2_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_2_act (Activatio (None, 6, 6, 32)     0           Block_4_Branch_2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_2_1_conv (Conv2D (None, 6, 6, 64)     6144        Block_4_Branch_2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_1_conv (Conv2D)  (None, 6, 6, 192)    98304       block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_2_1_bn (BatchNor (None, 6, 6, 64)     192         Block_4_Branch_2_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_1_bn (BatchNorma (None, 6, 6, 192)    576         Block_4_Branch_1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_2_1_act (Activat (None, 6, 6, 64)     0           Block_4_Branch_2_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_1_act (Activatio (None, 6, 6, 192)    0           Block_4_Branch_1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_2_2_conv (Conv2D (None, 6, 6, 64)     12288       Block_4_Branch_2_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_1_1_conv (Conv2D (None, 6, 6, 256)    147456      Block_4_Branch_1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_2_2_bn (BatchNor (None, 6, 6, 64)     192         Block_4_Branch_2_2_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_1_1_bn (BatchNor (None, 6, 6, 256)    768         Block_4_Branch_1_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_2_2_act (Activat (None, 6, 6, 64)     0           Block_4_Branch_2_2_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_1_1_act (Activat (None, 6, 6, 256)    0           Block_4_Branch_1_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_3 (MaxPooling2D) (None, 6, 6, 64)     0           Block_4_Branch_2_2_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_0_conv (Conv2D)  (None, 6, 6, 128)    65536       block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_1_2_conv (Conv2D (None, 6, 6, 256)    196608      Block_4_Branch_1_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_3_1_conv (Conv2D (None, 6, 6, 64)     4096        Block_4_Branch_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_0_bn (BatchNorma (None, 6, 6, 128)    384         Block_4_Branch_0_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_1_2_bn (BatchNor (None, 6, 6, 256)    768         Block_4_Branch_1_2_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_3_1_bn (BatchNor (None, 6, 6, 64)     192         Block_4_Branch_3_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_0_act (Activatio (None, 6, 6, 128)    0           Block_4_Branch_0_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_1_2_act (Activat (None, 6, 6, 256)    0           Block_4_Branch_1_2_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Branch_3_1_act (Activat (None, 6, 6, 64)     0           Block_4_Branch_3_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_4_Concatenated (Concatena (None, 6, 6, 512)    0           Block_4_Branch_0_act[0][0]       \n",
      "                                                                 Block_4_Branch_1_2_act[0][0]     \n",
      "                                                                 Block_4_Branch_2_2_act[0][0]     \n",
      "                                                                 Block_4_Branch_3_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_2_conv (Conv2D)  (None, 6, 6, 32)     16384       Block_4_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_2_bn (BatchNorma (None, 6, 6, 32)     96          Block_5_Branch_2_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_2_act (Activatio (None, 6, 6, 32)     0           Block_5_Branch_2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_2_1_conv (Conv2D (None, 6, 6, 64)     6144        Block_5_Branch_2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_1_conv (Conv2D)  (None, 6, 6, 192)    98304       Block_4_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_2_1_bn (BatchNor (None, 6, 6, 64)     192         Block_5_Branch_2_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_1_bn (BatchNorma (None, 6, 6, 192)    576         Block_5_Branch_1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_2_1_act (Activat (None, 6, 6, 64)     0           Block_5_Branch_2_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_1_act (Activatio (None, 6, 6, 192)    0           Block_5_Branch_1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_2_2_conv (Conv2D (None, 6, 6, 64)     12288       Block_5_Branch_2_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_1_1_conv (Conv2D (None, 6, 6, 256)    147456      Block_5_Branch_1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_2_2_bn (BatchNor (None, 6, 6, 64)     192         Block_5_Branch_2_2_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_1_1_bn (BatchNor (None, 6, 6, 256)    768         Block_5_Branch_1_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_2_2_act (Activat (None, 6, 6, 64)     0           Block_5_Branch_2_2_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_1_1_act (Activat (None, 6, 6, 256)    0           Block_5_Branch_1_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_3 (MaxPooling2D) (None, 6, 6, 64)     0           Block_5_Branch_2_2_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_0_conv (Conv2D)  (None, 6, 6, 128)    65536       Block_4_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_1_2_conv (Conv2D (None, 6, 6, 256)    196608      Block_5_Branch_1_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_3_1_conv (Conv2D (None, 6, 6, 64)     4096        Block_5_Branch_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_0_bn (BatchNorma (None, 6, 6, 128)    384         Block_5_Branch_0_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_1_2_bn (BatchNor (None, 6, 6, 256)    768         Block_5_Branch_1_2_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_3_1_bn (BatchNor (None, 6, 6, 64)     192         Block_5_Branch_3_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_0_act (Activatio (None, 6, 6, 128)    0           Block_5_Branch_0_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_1_2_act (Activat (None, 6, 6, 256)    0           Block_5_Branch_1_2_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Branch_3_1_act (Activat (None, 6, 6, 64)     0           Block_5_Branch_3_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_5_Concatenated (Concatena (None, 6, 6, 512)    0           Block_5_Branch_0_act[0][0]       \n",
      "                                                                 Block_5_Branch_1_2_act[0][0]     \n",
      "                                                                 Block_5_Branch_2_2_act[0][0]     \n",
      "                                                                 Block_5_Branch_3_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_2_conv (Conv2D)  (None, 6, 6, 32)     16384       Block_5_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_2_bn (BatchNorma (None, 6, 6, 32)     96          Block_6_Branch_2_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_2_act (Activatio (None, 6, 6, 32)     0           Block_6_Branch_2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_2_1_conv (Conv2D (None, 6, 6, 64)     6144        Block_6_Branch_2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_1_conv (Conv2D)  (None, 6, 6, 192)    98304       Block_5_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_2_1_bn (BatchNor (None, 6, 6, 64)     192         Block_6_Branch_2_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_1_bn (BatchNorma (None, 6, 6, 192)    576         Block_6_Branch_1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_2_1_act (Activat (None, 6, 6, 64)     0           Block_6_Branch_2_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_1_act (Activatio (None, 6, 6, 192)    0           Block_6_Branch_1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_2_2_conv (Conv2D (None, 6, 6, 64)     12288       Block_6_Branch_2_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_1_1_conv (Conv2D (None, 6, 6, 256)    147456      Block_6_Branch_1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_2_2_bn (BatchNor (None, 6, 6, 64)     192         Block_6_Branch_2_2_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_1_1_bn (BatchNor (None, 6, 6, 256)    768         Block_6_Branch_1_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_2_2_act (Activat (None, 6, 6, 64)     0           Block_6_Branch_2_2_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_1_1_act (Activat (None, 6, 6, 256)    0           Block_6_Branch_1_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_3 (MaxPooling2D) (None, 6, 6, 64)     0           Block_6_Branch_2_2_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_0_conv (Conv2D)  (None, 6, 6, 128)    65536       Block_5_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_1_2_conv (Conv2D (None, 6, 6, 256)    196608      Block_6_Branch_1_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_3_1_conv (Conv2D (None, 6, 6, 64)     4096        Block_6_Branch_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_0_bn (BatchNorma (None, 6, 6, 128)    384         Block_6_Branch_0_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_1_2_bn (BatchNor (None, 6, 6, 256)    768         Block_6_Branch_1_2_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_3_1_bn (BatchNor (None, 6, 6, 64)     192         Block_6_Branch_3_1_conv[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_0_act (Activatio (None, 6, 6, 128)    0           Block_6_Branch_0_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_1_2_act (Activat (None, 6, 6, 256)    0           Block_6_Branch_1_2_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Branch_3_1_act (Activat (None, 6, 6, 64)     0           Block_6_Branch_3_1_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block_6_Concatenated (Concatena (None, 6, 6, 512)    0           Block_6_Branch_0_act[0][0]       \n",
      "                                                                 Block_6_Branch_1_2_act[0][0]     \n",
      "                                                                 Block_6_Branch_2_2_act[0][0]     \n",
      "                                                                 Block_6_Branch_3_1_act[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 3, 3, 512)    0           Block_6_Concatenated[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 512)          0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 30)           15390       global_max_pooling2d_1[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 8,292,590\n",
      "Trainable params: 8,280,206\n",
      "Non-trainable params: 12,384\n",
      "__________________________________________________________________________________________________\n",
      "Model深度： 167\n"
     ]
    }
   ],
   "source": [
    "# 定義人臉關鍵點檢測網路\n",
    "model = VGG16_ResNet_Inception(include_top=False,input_shape=(96,96,1), classes=30)\n",
    "\n",
    "model.summary()\n",
    "print('Model深度：', len(model.layers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 配置 loss funtion 和 optimizer\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = imgs_train.copy()\n",
    "y_train = points_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cicicici_hsiao/anaconda3/envs/cv100/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 1712 samples, validate on 428 samples\n",
      "Epoch 1/20\n",
      "1712/1712 [==============================] - 42s 25ms/step - loss: 0.0398 - mean_absolute_error: 0.1673 - val_loss: 0.0515 - val_mean_absolute_error: 0.1835\n",
      "Epoch 2/20\n",
      "1712/1712 [==============================] - 12s 7ms/step - loss: 0.0309 - mean_absolute_error: 0.1482 - val_loss: 0.0676 - val_mean_absolute_error: 0.1999\n",
      "Epoch 3/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0274 - mean_absolute_error: 0.1411 - val_loss: 0.0713 - val_mean_absolute_error: 0.2030\n",
      "Epoch 4/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0258 - mean_absolute_error: 0.1392 - val_loss: 0.0601 - val_mean_absolute_error: 0.1923\n",
      "Epoch 5/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0250 - mean_absolute_error: 0.1382 - val_loss: 0.0589 - val_mean_absolute_error: 0.1908\n",
      "Epoch 6/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0245 - mean_absolute_error: 0.1374 - val_loss: 0.0466 - val_mean_absolute_error: 0.1771\n",
      "Epoch 7/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0243 - mean_absolute_error: 0.1374 - val_loss: 0.0442 - val_mean_absolute_error: 0.1737\n",
      "Epoch 8/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0240 - mean_absolute_error: 0.1367 - val_loss: 0.0457 - val_mean_absolute_error: 0.1754\n",
      "Epoch 9/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0239 - mean_absolute_error: 0.1364 - val_loss: 0.0410 - val_mean_absolute_error: 0.1691\n",
      "Epoch 10/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0239 - mean_absolute_error: 0.1364 - val_loss: 0.0397 - val_mean_absolute_error: 0.1669\n",
      "Epoch 11/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0239 - mean_absolute_error: 0.1364 - val_loss: 0.0411 - val_mean_absolute_error: 0.1678\n",
      "Epoch 12/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0238 - mean_absolute_error: 0.1363 - val_loss: 0.0330 - val_mean_absolute_error: 0.1549\n",
      "Epoch 13/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0238 - mean_absolute_error: 0.1363 - val_loss: 0.0313 - val_mean_absolute_error: 0.1512\n",
      "Epoch 14/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0237 - mean_absolute_error: 0.1362 - val_loss: 0.0313 - val_mean_absolute_error: 0.1519\n",
      "Epoch 15/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0237 - mean_absolute_error: 0.1361 - val_loss: 0.0309 - val_mean_absolute_error: 0.1502\n",
      "Epoch 16/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0236 - mean_absolute_error: 0.1360 - val_loss: 0.0272 - val_mean_absolute_error: 0.1433\n",
      "Epoch 17/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0237 - mean_absolute_error: 0.1361 - val_loss: 0.0281 - val_mean_absolute_error: 0.1453\n",
      "Epoch 18/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0238 - mean_absolute_error: 0.1363 - val_loss: 0.0274 - val_mean_absolute_error: 0.1441\n",
      "Epoch 19/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0236 - mean_absolute_error: 0.1360 - val_loss: 0.0268 - val_mean_absolute_error: 0.1430\n",
      "Epoch 20/20\n",
      "1712/1712 [==============================] - 11s 7ms/step - loss: 0.0235 - mean_absolute_error: 0.1358 - val_loss: 0.0259 - val_mean_absolute_error: 0.1411\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train, validation_split = 0.2, shuffle=True, batch_size=256,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MAE')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history[\"mean_absolute_error\"], \"red\", label=\"MAE\")\n",
    "ax.plot(history.history[\"val_mean_absolute_error\"], \"blue\", label=\"val MAE\")\n",
    "legend = ax.legend(loc='upper right', shadow=True, fontsize='small')\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
